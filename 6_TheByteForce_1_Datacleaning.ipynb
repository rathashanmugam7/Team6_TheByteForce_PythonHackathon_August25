{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be0e7ec3-7b3d-4874-a7b4-1efafdfc7c83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ§¼ Cleaning HUPA0001P.csv\n",
      "âœ… Saved: C:\\PYTHON HACK\\Cleaned_data\\cleaned_HUPA0001P.csv\n",
      "ðŸ§¼ Cleaning HUPA0002P.csv\n",
      "âœ… Saved: C:\\PYTHON HACK\\Cleaned_data\\cleaned_HUPA0002P.csv\n",
      "ðŸ§¼ Cleaning HUPA0003P.csv\n",
      "âœ… Saved: C:\\PYTHON HACK\\Cleaned_data\\cleaned_HUPA0003P.csv\n",
      "ðŸ§¼ Cleaning HUPA0004P.csv\n",
      "âœ… Saved: C:\\PYTHON HACK\\Cleaned_data\\cleaned_HUPA0004P.csv\n",
      "ðŸ§¼ Cleaning HUPA0005P.csv\n",
      "âœ… Saved: C:\\PYTHON HACK\\Cleaned_data\\cleaned_HUPA0005P.csv\n",
      "ðŸ§¼ Cleaning HUPA0006P.csv\n",
      "âœ… Saved: C:\\PYTHON HACK\\Cleaned_data\\cleaned_HUPA0006P.csv\n",
      "ðŸ§¼ Cleaning HUPA0007P.csv\n",
      "âœ… Saved: C:\\PYTHON HACK\\Cleaned_data\\cleaned_HUPA0007P.csv\n",
      "ðŸ§¼ Cleaning HUPA0009P.csv\n",
      "âœ… Saved: C:\\PYTHON HACK\\Cleaned_data\\cleaned_HUPA0009P.csv\n",
      "ðŸ§¼ Cleaning HUPA0010P.csv\n",
      "âœ… Saved: C:\\PYTHON HACK\\Cleaned_data\\cleaned_HUPA0010P.csv\n",
      "ðŸ§¼ Cleaning HUPA0011P.csv\n",
      "âœ… Saved: C:\\PYTHON HACK\\Cleaned_data\\cleaned_HUPA0011P.csv\n",
      "ðŸ§¼ Cleaning HUPA0014P.csv\n",
      "âœ… Saved: C:\\PYTHON HACK\\Cleaned_data\\cleaned_HUPA0014P.csv\n",
      "ðŸ§¼ Cleaning HUPA0015P.csv\n",
      "âœ… Saved: C:\\PYTHON HACK\\Cleaned_data\\cleaned_HUPA0015P.csv\n",
      "ðŸ§¼ Cleaning HUPA0016P.csv\n",
      "âœ… Saved: C:\\PYTHON HACK\\Cleaned_data\\cleaned_HUPA0016P.csv\n",
      "ðŸ§¼ Cleaning HUPA0017P.csv\n",
      "âœ… Saved: C:\\PYTHON HACK\\Cleaned_data\\cleaned_HUPA0017P.csv\n",
      "ðŸ§¼ Cleaning HUPA0018P.csv\n",
      "âœ… Saved: C:\\PYTHON HACK\\Cleaned_data\\cleaned_HUPA0018P.csv\n",
      "ðŸ§¼ Cleaning HUPA0019P.csv\n",
      "âœ… Saved: C:\\PYTHON HACK\\Cleaned_data\\cleaned_HUPA0019P.csv\n",
      "ðŸ§¼ Cleaning HUPA0020P.csv\n",
      "âœ… Saved: C:\\PYTHON HACK\\Cleaned_data\\cleaned_HUPA0020P.csv\n",
      "ðŸ§¼ Cleaning HUPA0021P.csv\n",
      "âœ… Saved: C:\\PYTHON HACK\\Cleaned_data\\cleaned_HUPA0021P.csv\n",
      "ðŸ§¼ Cleaning HUPA0022P.csv\n",
      "âœ… Saved: C:\\PYTHON HACK\\Cleaned_data\\cleaned_HUPA0022P.csv\n",
      "ðŸ§¼ Cleaning HUPA0023P.csv\n",
      "âœ… Saved: C:\\PYTHON HACK\\Cleaned_data\\cleaned_HUPA0023P.csv\n",
      "ðŸ§¼ Cleaning HUPA0024P.csv\n",
      "âœ… Saved: C:\\PYTHON HACK\\Cleaned_data\\cleaned_HUPA0024P.csv\n",
      "ðŸ§¼ Cleaning HUPA0025P.csv\n",
      "âœ… Saved: C:\\PYTHON HACK\\Cleaned_data\\cleaned_HUPA0025P.csv\n",
      "ðŸ§¼ Cleaning HUPA0026P.csv\n",
      "âœ… Saved: C:\\PYTHON HACK\\Cleaned_data\\cleaned_HUPA0026P.csv\n",
      "ðŸ§¼ Cleaning HUPA0027P.csv\n",
      "âœ… Saved: C:\\PYTHON HACK\\Cleaned_data\\cleaned_HUPA0027P.csv\n",
      "ðŸ§¼ Cleaning HUPA0028P.csv\n",
      "âœ… Saved: C:\\PYTHON HACK\\Cleaned_data\\cleaned_HUPA0028P.csv\n",
      "ðŸ§¼ Cleaning T1DM_patient_sleep_demographics_with_race.csv\n",
      "âœ… Saved: C:\\PYTHON HACK\\Cleaned_data\\cleaned_T1DM_patient_sleep_demographics_with_race.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "                                        # ------------------------------#\n",
    "                                              # DATA PRE-PROCESSING #\n",
    "                                        #-------------------------------#\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\", UserWarning)\n",
    "\n",
    "\n",
    "#Merging all patients Diabietes Dataset into one file. \n",
    "#Combined all patient files into one.\n",
    "#This code loads all CSV files and combines them into a single consolidated dataset.\n",
    "\n",
    "\n",
    "# Folder containing all raw patient files\n",
    "raw_folder = r'C:\\PYTHON HACK'\n",
    "cleaned_folder = r'C:\\PYTHON HACK\\Cleaned_data'\n",
    "os.makedirs(cleaned_folder, exist_ok=True)\n",
    "\n",
    "# Loop through all CSVs\n",
    "for file in os.listdir(raw_folder):\n",
    "    if file.lower().endswith('.csv'):\n",
    "        file_path = os.path.join(raw_folder, file)\n",
    "        print(f\"ðŸ§¼ Cleaning {file}\")\n",
    "\n",
    "        try:\n",
    "            # Load with flexible delimiter handling\n",
    "            df = pd.read_csv(file_path, sep=None, engine='python', on_bad_lines='skip')\n",
    "\n",
    "            # Standardize column names\n",
    "            df.columns = [col.strip().lower().replace(' ', '_') for col in df.columns]\n",
    "\n",
    "            # Parse time column if present\n",
    "            time_cols = [col for col in df.columns if 'time' in col]\n",
    "            if time_cols:\n",
    "                df[time_cols[0]] = pd.to_datetime(df[time_cols[0]], errors='coerce')\n",
    "                df.dropna(subset=[time_cols[0]], inplace=True)\n",
    "\n",
    "            # Drop fully empty rows\n",
    "            df.dropna(how='all', inplace=True)\n",
    "\n",
    "            # Save cleaned file\n",
    "            cleaned_path = os.path.join(cleaned_folder, f'cleaned_{file}')\n",
    "            df.to_csv(cleaned_path, index=False)\n",
    "            print(f\"âœ… Saved: {cleaned_path}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Failed to clean {file}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b35e08b-090b-4ca2-bece-e6841c2afc46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Merged file saved at: C:\\PYTHON HACK\\Cleaned_data\\merged_patients.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Path to cleaned files\n",
    "cleaned_folder = r'C:\\PYTHON HACK\\Cleaned_data'\n",
    "\n",
    "# Grab all patient files (excluding demographics)\n",
    "patient_files = glob.glob(os.path.join(cleaned_folder, 'cleaned_HUPA*.csv'))\n",
    "\n",
    "# Merge all into one DataFrame\n",
    "merged_df = pd.concat([pd.read_csv(f) for f in patient_files], ignore_index=True)\n",
    "\n",
    "# Optional: Add filename as patient ID if not already present\n",
    "merged_df['source_file'] = [os.path.basename(f) for f in patient_files for _ in range(len(pd.read_csv(f)))]\n",
    "\n",
    "# Save merged file\n",
    "merged_path = os.path.join(cleaned_folder, 'merged_patients.csv')\n",
    "merged_df.to_csv(merged_path, index=False)\n",
    "\n",
    "print(f\"âœ… Merged file saved at: {merged_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "26f28b38-bfeb-429e-b81a-af930d53920f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# regex extraction\n",
    "merged_df['patient_id'] = merged_df['source_file'].str.extract(r'(HUPA\\d{4}P)')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c4c5d24c-8cdb-4f30-b081-a4a2be7da0d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Read and merge all CSVs into one DataFrame\n",
    "all_files = glob.glob(r'C:\\PYTHON HACK\\Cleaned_data\\cleaned_HUPA*.csv')\n",
    "merged_df = pd.concat([pd.read_csv(f) for f in all_files], ignore_index=True)\n",
    "merged_df.to_csv(r'C:\\PYTHON HACK\\Cleaned_data\\merged_patients.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "87cce8bb-20fd-4c85-b261-8a0420a024e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Add source file name to each row\n",
    "merged_df['source_file'] = [os.path.basename(f) for f in all_files for _ in range(len(pd.read_csv(f)))]\n",
    "\n",
    "# Extract patient_id from filename (e.g., HUPA0001P)\n",
    "merged_df['patient_id'] = merged_df['source_file'].str.extract(r'(HUPA\\d{4}P)')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4ada5d58-f229-4753-9b2e-03e83958e7d5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matched rows: 309392\n",
      "Unmatched rows: 0\n"
     ]
    }
   ],
   "source": [
    "print(\"Matched rows:\", final_df['age'].notna().sum())\n",
    "print(\"Unmatched rows:\", final_df['age'].isna().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee4c3df0-4f40-437e-bf94-4f6955f7e7e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Time features added and saved to Excel!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# A copy of the merged dataset is created to preserve the original.\n",
    "# The time column is converted to date, time ,hour and days of week\n",
    "# This allows us to easily to analysis Glucose spikes by hour, Activity trends by weekday,Insulin delivery timing\n",
    "\n",
    "\n",
    "# Convert 'time' column to datetime format\n",
    "df['time'] = pd.to_datetime(df['time'], errors='coerce')\n",
    "\n",
    "# Create new columns\n",
    "df['date'] = df['time'].dt.date\n",
    "df['clock_time'] = df['time'].dt.time\n",
    "df['hour'] = df['time'].dt.hour\n",
    "df['day_of_week'] = df['time'].dt.day_name()\n",
    "\n",
    "# Save the updated dataset to Excel\n",
    "df.to_excel(r'C:\\PYTHON HACK\\Cleaned_data\\final_dataset_with_time_features.xlsx', index=False)\n",
    "\n",
    "print(\"âœ… Time features added and saved to Excel!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b6b8613-b6be-473b-bd5d-e90d9e4e6420",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Glucose features added and saved!\n"
     ]
    }
   ],
   "source": [
    "# Glucose Cleaning, Flagging, and Conversion\n",
    "\n",
    "# Step 1: Fill missing glucose values with the median\n",
    "df['glucose'] = df['glucose'].fillna(df['glucose'].median())\n",
    "\n",
    "# Step 2: Flag glucose levels\n",
    "df['glucose_flag'] = pd.cut(\n",
    "    df['glucose'],\n",
    "    bins=[0, 70, 180, 300],\n",
    "    labels=['Low', 'Normal', 'High'],\n",
    "    include_lowest=True\n",
    ")\n",
    "\n",
    "# Step 3: Convert mg/dL to mmol/L (1 mmol/L = 18 mg/dL)\n",
    "df['glucose_mmol'] = df['glucose'] / 18\n",
    "\n",
    "# Optional: Round mmol values for cleaner display\n",
    "df['glucose_mmol'] = df['glucose_mmol'].round(2)\n",
    "\n",
    "# Save updated file\n",
    "df.to_excel(r'C:\\PYTHON HACK\\Cleaned_data\\final_dataset_with_glucose.xlsx', index=False)\n",
    "\n",
    "print(\"âœ… Glucose features added and saved!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f7dad0e8-3d3e-46d9-8eea-b649f351fbac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize calories to a 0â€“1 scale\n",
    "df['calories_norm'] = (df['calories'] - df['calories'].min()) / (df['calories'].max() - df['calories'].min())\n",
    "\n",
    "# Flag days with high calorie burn\n",
    "df['high_burn'] = df['calories'] > 2500\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a9fa2cc1-7f90-4c55-9852-edf398fdcba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply rolling average with a window of 5 readings\n",
    "df['hr_rolling'] = df['heart_rate'].rolling(window=5, min_periods=1).mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e19d3f70-015c-4c1b-8b78-f11775f24bdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Heart rate smoothed and saved!\n"
     ]
    }
   ],
   "source": [
    "# Rolling Average for Heart Rate\n",
    "#Heart rate data can be noisy â€” especially if it's collected frequently (e.g., every few seconds or minutes).\n",
    "#A rolling average helps: Smooth out short-term fluctuations\n",
    "#Highlight trends over time (e.g., resting vs active periods)\n",
    "#Make visualizations cleaner and more interpretable\n",
    "#This is especially useful in dashboards or time-series plots where spikes can distract from the overall pattern.\n",
    "\n",
    "# Step 1: Convert 'time' column to datetime if not already\n",
    "df['time'] = pd.to_datetime(df['time'], errors='coerce')\n",
    "\n",
    "# Step 2: Sort by time to ensure rolling window follows chronological order\n",
    "df = df.sort_values('time')\n",
    "\n",
    "# Step 3: Apply rolling average with a window of 5 readings\n",
    "df['hr_rolling'] = df['heart_rate'].rolling(window=5, min_periods=1).mean()\n",
    "\n",
    "# Optional: Round for cleaner display\n",
    "df['hr_rolling'] = df['hr_rolling'].round(2)\n",
    "\n",
    "# Save the updated file\n",
    "df.to_excel(r'C:\\PYTHON HACK\\Cleaned_data\\final_dataset_with_hr_smooth.xlsx', index=False)\n",
    "\n",
    "print(\"âœ… Heart rate smoothed and saved!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "26cf47a0-8e70-4357-9806-ca43ba29c163",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['patient_id', 'time', 'glucose', 'calories', 'heart_rate', 'steps', 'basal_rate', 'bolus_volume_delivered', 'carb_input', 'age', 'gender', 'race', 'average_sleep_duration_(hrs)', 'sleep_quality_(1-10)', '%_with_sleep_disturbances', 'hr_rolling']\n"
     ]
    }
   ],
   "source": [
    "print(df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4f1ee013-947b-455f-8f3c-1d3ccb82f6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# conversion of patient_id into string type \n",
    "df['patient_id'] = df['patient_id'].astype('string')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c71de691-643b-4411-9d2a-8aa6bf000460",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method DataFrame.info of        patient_id                time  glucose  calories  heart_rate  steps  \\\n",
      "0       HUPA0001P 2018-06-13 18:40:00      332   6.35950          82     34   \n",
      "1       HUPA0001P 2018-06-13 18:45:00      326   7.72800          83      0   \n",
      "2       HUPA0001P 2018-06-13 18:50:00      330   4.74950          80      0   \n",
      "3       HUPA0001P 2018-06-13 18:55:00      324   6.35950          89     20   \n",
      "4       HUPA0001P 2018-06-13 19:00:00      306   5.15200          92      0   \n",
      "...           ...                 ...      ...       ...         ...    ...   \n",
      "309387  HUPA0028P 2022-05-18 11:55:00      109  10.79280         104      0   \n",
      "309388  HUPA0028P 2022-05-18 12:00:00      114   9.80346         103      0   \n",
      "309389  HUPA0028P 2022-05-18 12:05:00      118   5.66622          95      0   \n",
      "309390  HUPA0028P 2022-05-18 12:10:00      123   5.57628          91      0   \n",
      "309391  HUPA0028P 2022-05-18 12:15:00      128   5.57628          99      0   \n",
      "\n",
      "        basal_rate  bolus_volume_delivered  carb_input  age gender   race  \\\n",
      "0         0.091667                     0.0         0.0   34   Male  Other   \n",
      "1         0.091667                     0.0         0.0   34   Male  Other   \n",
      "2         0.091667                     0.0         0.0   34   Male  Other   \n",
      "3         0.091667                     0.0         0.0   34   Male  Other   \n",
      "4         0.075000                     0.0         0.0   34   Male  Other   \n",
      "...            ...                     ...         ...  ...    ...    ...   \n",
      "309387    0.000000                     0.0         0.0   62   Male  Black   \n",
      "309388    0.000000                     0.0         0.0   62   Male  Black   \n",
      "309389    0.000000                     0.0         0.0   62   Male  Black   \n",
      "309390    0.000000                     0.0         0.0   62   Male  Black   \n",
      "309391    0.000000                     0.0         0.0   62   Male  Black   \n",
      "\n",
      "        average_sleep_duration_(hrs)  sleep_quality_(1-10)  \\\n",
      "0                                6.3                   4.5   \n",
      "1                                6.3                   4.5   \n",
      "2                                6.3                   4.5   \n",
      "3                                6.3                   4.5   \n",
      "4                                6.3                   4.5   \n",
      "...                              ...                   ...   \n",
      "309387                           5.1                   7.9   \n",
      "309388                           5.1                   7.9   \n",
      "309389                           5.1                   7.9   \n",
      "309390                           5.1                   7.9   \n",
      "309391                           5.1                   7.9   \n",
      "\n",
      "        %_with_sleep_disturbances  hr_rolling  \n",
      "0                              80       82.32  \n",
      "1                              80       83.03  \n",
      "2                              80       82.20  \n",
      "3                              80       83.93  \n",
      "4                              80       85.64  \n",
      "...                           ...         ...  \n",
      "309387                         30       93.12  \n",
      "309388                         30       97.17  \n",
      "309389                         30       98.80  \n",
      "309390                         30       98.86  \n",
      "309391                         30       98.76  \n",
      "\n",
      "[309392 rows x 16 columns]>\n"
     ]
    }
   ],
   "source": [
    "#conversion of numeric into INT(glucose,steps,heart_rate)\n",
    "df = df.astype({'glucose': int, 'steps':int,'heart_rate': int})\n",
    "print(df.info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "89f2a27a-5ac7-4567-bd6d-8dc24e96a8da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 309392 entries, 0 to 309391\n",
      "Data columns (total 16 columns):\n",
      " #   Column                        Non-Null Count   Dtype         \n",
      "---  ------                        --------------   -----         \n",
      " 0   patient_id                    309392 non-null  string        \n",
      " 1   time                          309392 non-null  datetime64[ns]\n",
      " 2   glucose                       309392 non-null  int32         \n",
      " 3   calories                      309392 non-null  float64       \n",
      " 4   heart_rate                    309392 non-null  int32         \n",
      " 5   steps                         309392 non-null  int32         \n",
      " 6   basal_rate                    309392 non-null  float64       \n",
      " 7   bolus_volume_delivered        309392 non-null  float64       \n",
      " 8   carb_input                    309392 non-null  float64       \n",
      " 9   age                           309392 non-null  int64         \n",
      " 10  gender                        309392 non-null  object        \n",
      " 11  race                          309392 non-null  object        \n",
      " 12  average_sleep_duration_(hrs)  309392 non-null  float64       \n",
      " 13  sleep_quality_(1-10)          309392 non-null  float64       \n",
      " 14  %_with_sleep_disturbances     309392 non-null  int64         \n",
      " 15  hr_rolling                    309392 non-null  float64       \n",
      "dtypes: datetime64[ns](1), float64(7), int32(3), int64(2), object(2), string(1)\n",
      "memory usage: 36.6+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Round float columns to two decimal places: \n",
    "The columns calories, basal_rate, bolus_volume_delivered, and carb_input are rounded to two decimal places using .round(). \n",
    "This standardizes the numeric precision, making the data easier to read and interpret, while maintaining sufficient accuracy for analysis.\n",
    "df = df.round({'calories': 2, 'basal_rate': 2,'bolus_volume_delivered': 2,'carb_input': 2 })\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "25d1e0ac-65be-47cb-b281-5a17ab9d970f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "patient_id                      0\n",
       "time                            0\n",
       "glucose                         0\n",
       "calories                        0\n",
       "heart_rate                      0\n",
       "steps                           0\n",
       "basal_rate                      0\n",
       "bolus_volume_delivered          0\n",
       "carb_input                      0\n",
       "age                             0\n",
       "gender                          0\n",
       "race                            0\n",
       "average_sleep_duration_(hrs)    0\n",
       "sleep_quality_(1-10)            0\n",
       "%_with_sleep_disturbances       0\n",
       "hr_rolling                      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking for null (missing) values.It is an essential step in data cleaning because missing data can lead to errors, inaccurate calculations, or biased analysis\n",
    "#Identifying null values allows you to decide how to handle these values.\n",
    "df.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2dfa5ccf-5e82-4202-89bf-791fbece8dc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate rows: 0\n"
     ]
    }
   ],
   "source": [
    "#Checking for the duplicate rows\n",
    "#Duplicate rows can lead to biased results, incorrect statistics, and misleading insights.\n",
    "#Checking for duplicates ensures data integrity by identifying and removing repeated records, so the analysis reflects accurate and unique\n",
    "\n",
    "\n",
    "# Returns True for rows that are duplicates\n",
    "duplicates = df.duplicated()\n",
    "\n",
    "# Count total duplicates\n",
    "print(\"Number of duplicate rows:\", duplicates.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a5be0668-2ed1-4d9a-bb7a-73ddf2c93905",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "glucose: below=0, above=104\n",
      "heart_rate: below=12, above=0\n",
      "steps: below=0, above=0\n",
      "calories: below=0, above=0\n",
      "basal_rate: below=0, above=0\n",
      "bolus_volume_delivered: below=4, above=0\n",
      "carb_input: below=0, above=0\n"
     ]
    }
   ],
   "source": [
    "# Always check the outliers finding the outliers in the dataset is.\n",
    "#Outliers are data points that differ significantly from the majority of observations.\n",
    "#They can skew results, distort averages, or affect machine learning models.\n",
    "#Identifying outliers helps in deciding whether to investigate, correct, or\n",
    "#remove them to improve data quality and reliability of analysis.\n",
    "\n",
    "clip_ranges = {\n",
    "    \"glucose\": (40, 400), # mg/dL\n",
    "    \"heart_rate\": (40, 200), # bpm\n",
    "    \"steps\": (0, 1000), # steps in 5 min\n",
    "    \"calories\": (0, 1000),# kcal in 5 min\n",
    "    \"basal_rate\": (0, 20), # units/hour\n",
    "    \"bolus_volume_delivered\": (0, 25), # units per 5 min\n",
    "    \"carb_input\": (0, 300), # grams in 5 min\n",
    "}\n",
    "\n",
    " for col, (low, high) in clip_ranges.items():\n",
    "\n",
    "    if col in df.columns:\n",
    "        below = (df[col] < low).sum() if low is not None else 0\n",
    "        above = (df[col] > high).sum() if high is not None else 0\n",
    "        print(f\"{col}: below={below}, above={above}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bc71d436-c678-4e75-aa1e-61bcab2abda5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  patient_id  age  gender             race  average_sleep_duration_(hrs)  \\\n",
      "0  HUPA0001P   34    Male            Other                           6.3   \n",
      "1  HUPA0002P   49    Male         Hispanic                           6.6   \n",
      "2  HUPA0003P   64    Male            Black                           5.3   \n",
      "3  HUPA0004P   34  Female  Native American                           5.2   \n",
      "4  HUPA0005P   49    Male  Native American                           5.8   \n",
      "\n",
      "   sleep_quality_(1-10)  %_with_sleep_disturbances  \n",
      "0                   4.5                         80  \n",
      "1                   4.4                         40  \n",
      "2                   5.2                         70  \n",
      "3                   6.9                         60  \n",
      "4                   7.9                         30  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "#The cleaned and processed DataFrame is exported to a CSV file named Cleaned_T1DM_patient)demographics.csv \n",
    "#The 'index=False' parameter ensures that row numbers are not included in the saved file.\n",
    "#This creates a ready-to-use dataset for further analysis or modeling.\n",
    "\n",
    "df_demographics = pd.read_csv(r'C:\\PYTHON HACK\\Cleaned_data\\cleaned_T1DM_patient_demographics.csv')\n",
    "df_demographics.to_csv(\"cleaned_T1DM_patient_demographics.csv\", index=False)\n",
    "print(df_demographics.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15008911-55ef-4ad4-96ad-9f32aac492a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
